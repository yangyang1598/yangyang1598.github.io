{"pages":[],"posts":[{"title":"The first day I made hexo","text":"github 연동 hexo 생성 1일차 좋은 포트폴리오 제작을 위해 꾸준히 업로드 할 수 있도록 하자. hexo generate-&gt; 정적 리소스 생성hexo deploy-&gt;배포( 다른 사람이 내 링크를 통해 접근 가능하도록 함) ~~ 또는 ‘’’ ‘’’ 등을 무시하고 싶을때는 ~Hi~ 등으로 표현 가능","link":"/2021/10/19/hello-world/"},{"title":"team프로젝트 코드","text":"team project main code 차선 검출 및 고속도로 주행 내 객체 인식 개발 환경: YOLOV3, python ,opencv 중요 함수123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263def Yolo(img, score, nms): height, width = img.shape[:2] yolo_net = cv2.dnn.readNet('YOLO/yolov3.weights', 'YOLO/yolov3.cfg') layer_names = yolo_net.getLayerNames() output_layers = [layer_names[i[0] - 1] for i in yolo_net.getUnconnectedOutLayers()] blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False) yolo_net.setInput(blob) outs = yolo_net.forward(output_layers) class_ids = [] confidences = [] boxes = [] for out in outs: for detection in out: scores = detection[5:] class_id = np.argmax(scores) confidence = scores[class_id] # 검출 신뢰도 if confidence &gt; 0.5: # Object detected # 검출기의 경계상자 좌표는 0 ~ 1로 정규화되어있으므로 다시 전처리 center_x = int(detection[0] * width) center_y = int(detection[1] * height) dw = int(detection[2] * width) dh = int(detection[3] * height) # Rectangle coordinate x = int(center_x - dw / 2) y = int(center_y - dh / 2) boxes.append([x, y, dw, dh]) confidences.append(float(confidence)) class_ids.append(class_id) indexes = cv2.dnn.NMSBoxes(boxes, confidences, score, nms) for i in range(len(boxes)): if i in indexes: x, y, w, h = boxes[i] label = str(classes[class_ids[i]]) score = confidences[i] text = f'{label} {score:.2f}' # 경계상자와 클래스 정보 투영 cv2.rectangle(img, (x, y), (x + w, y + h), (50, 50, 50), 2) cv2.rectangle(img, (x, y - 19), (int(x + len(text) * 2 * 4.5), y - 18 + len(text) * 2), (50, 50, 50), -1) cv2.putText(img, text, (x, y - 5), cv2.FONT_ITALIC, 0.5, (255, 255, 255), 2) return img passclasses = [&quot;person&quot;, &quot;bicycle&quot;, &quot;car&quot;, &quot;motorcycle&quot;, &quot;airplane&quot;, &quot;bus&quot;, &quot;train&quot;, &quot;truck&quot;, &quot;boat&quot;, &quot;traffic light&quot;, &quot;fire hydrant&quot;, &quot;stop sign&quot;, &quot;parking meter&quot;, &quot;bench&quot;, &quot;bird&quot;, &quot;cat&quot;, &quot;dog&quot;, &quot;horse&quot;, &quot;sheep&quot;, &quot;cow&quot;, &quot;elephant&quot;, &quot;bear&quot;, &quot;zebra&quot;, &quot;giraffe&quot;, &quot;backpack&quot;, &quot;umbrella&quot;, &quot;handbag&quot;, &quot;tie&quot;, &quot;suitcase&quot;, &quot;frisbee&quot;, &quot;skis&quot;, &quot;snowboard&quot;, &quot;sports ball&quot;, &quot;kite&quot;, &quot;baseball bat&quot;, &quot;baseball glove&quot;, &quot;skateboard&quot;, &quot;surfboard&quot;, &quot;tennis racket&quot;, &quot;bottle&quot;, &quot;wine glass&quot;, &quot;cup&quot;, &quot;fork&quot;, &quot;knife&quot;, &quot;spoon&quot;, &quot;bowl&quot;, &quot;banana&quot;, &quot;apple&quot;, &quot;sandwich&quot;, &quot;orange&quot;, &quot;broccoli&quot;, &quot;carrot&quot;, &quot;hot dog&quot;, &quot;pizza&quot;, &quot;donut&quot;, &quot;cake&quot;, &quot;chair&quot;, &quot;couch&quot;, &quot;potted plant&quot;, &quot;bed&quot;, &quot;dining table&quot;, &quot;toilet&quot;, &quot;tv&quot;, &quot;laptop&quot;, &quot;mouse&quot;, &quot;remote&quot;, &quot;keyboard&quot;, &quot;cell phone&quot;, &quot;microwave&quot;, &quot;oven&quot;, &quot;toaster&quot;, &quot;sink&quot;, &quot;refrigerator&quot;, &quot;book&quot;, &quot;clock&quot;, &quot;vase&quot;, &quot;scissors&quot;, &quot;teddy bear&quot;, &quot;hair drier&quot;, &quot;toothbrush&quot;] 차선 인식 오류 12345678910111213141516171819202122if len(left_lane_inds) == 0: for i in range(len(leftx_)): if len(leftx_[-(i + 1)]) != 0: leftx = leftx_[-(i + 1)] lefty = lefty_[-(i + 1)] print(&quot;왼쪽 에러&quot;) break pass passif len(right_lane_inds) == 0: for i in range(len(rightx_)): if len(rightx_[-(i + 1)]) != 0: rightx = rightx_[-(i + 1)] righty = righty_[-(i + 1)] print(&quot;오른쪽 에러&quot;) break pass pass pass 차선 이탈 검출 및 출력 123456789101112131415161718192021222324left_center = np.int_(np.mean(left_fitx))right_center = np.int_(np.mean(right_fitx))mid_center = np.int_(np.mean(mid_fitx))road_center = width // 2road_pixel = road_width / (right_center - left_center)error = mid_center - road_centererror_pixel = error * road_pixelif error &gt; 0: cv2.putText(img_result, f'right : {abs(error_pixel):.2f}m', (width // 2 - 50, height // 2 + 200), cv2.FONT_ITALIC, 0.5, (0, 0, 255), 2)elif error &lt; 0: cv2.putText(img_result, f'left : {abs(error_pixel):.2f}m', (width // 2 - 50, height // 2 + 200), cv2.FONT_ITALIC, 0.5, (0, 0, 255), 2)elif error == 0: cv2.putText(img_result, f'center', (width // 2, height // 2), cv2.FONT_ITALIC, 0.5, (0, 0, 255), 2)cv2.putText(img_result, f'{frame} / {frame_end}', (20, height - 40), cv2.FONT_ITALIC, 0.5, (255, 255, 255), 2)cv2.putText(img_result, f'{frame_count} / {frame_end * 3}', (20, height - 20), cv2.FONT_ITALIC, 0.5, (255, 255, 255), 2) 코드 알고리즘 실행 영상 차선인식 프로젝트 영상 참고문헌 및 사이트 [1] S.W. Jeon, D.S. Kim, “YOLO-based lane detection system”, Journal of the Korea Institute of Information andCommunication Engineering, Vol. 25, No. 3, pp. 464-470, Mar. 2021. [2] 큐 Queue, 「[Python3]OpenCV 곡선 차선 인식 프로젝트 - 차선 인식(1)」, 『큐의 Qrirosity Log』,https://m.blog.naver.com/PostView.naver?blogId=hirit808&amp;logNo=221486800161&amp;proxyReferer=, 2021.10.02검색 [3] 봉식이 누나, 「Python으로 OpenCV를 사용하여 YOLO Object detection」,『봉식이와 캔따개』,https://bong-sik.tistory.com/m/16, 2021.10.08 검색 [4] 「 [분석] YOLO 」, 『 Hello Blog!』, https://curt-park.github.io/2017-03-26/yolo/ ,2021.10.13 검색","link":"/2021/10/19/team%20code/"},{"title":"개발자로써 익혀야 할 것들","text":"리눅스 명령어 모음git bash를 다루기 위해서는 리눅스 명령어 More : LINUX 명령어 모음 머신러닝 직군 질문모음개발자 및 머신러닝 직군의 면접 예상 질문 More : 개발자 면접질문 강사님 캐글강사님 캐글의 예시 글 More:강사님 TPS-April 파이토치 입문파이토치 : 2016년에 발표된 딥러닝을 구현을 위한 파이썬 기반의 오픈소스 머신러닝 라이브러리TensorFlow와 같이 오픈소스로써 제공됨. More:파이토치 입문","link":"/2021/10/19/tip/"},{"title":"파이토치 실습 및 코드","text":"GPU 환경으로 변경12345import torchif torch.cuda.is_available(): device = torch.device(&quot;cuda:0&quot;) 데이터 셋 구성 1234from torchvision import datasetsPATH_DATA = &quot;./data&quot;train_data = datasets.MNIST(PATH_DATA, train = True, download=True) -입력 데이터 및 대상 label 추출 12345678910X_train, y_train = train_data.data, train_data.targetsprint(X_train.shape)print(y_train.shape)val_data = datasets.MNIST(PATH_DATA, train = False, download=True)print(val_data) #X_val, y_val = val_data.data, val_data.targetsprint(X_val.shape)print(y_val.shape) 12345678910if len(X_train.shape) == 3: # 1인 차원을 생성(10,2,7-&gt;10,1,2,7) # squeeze의 경우 1인 차원을 삭제함(3,1,2-&gt;3,2) X_train = X_train.unsqueeze(1) print(X_train.shape)if len(X_val.shape) == 3: X_val = X_val.unsqueeze(1) print(X_val.shape) 데이터 시각화 진행 12345678910111213141516171819from torchvision import utilsimport matplotlib.pyplot as pltimport numpy as np%matplotlib inlinedef show(img): # convert tensor to numpy array np_img = img.numpy() # Convert to H * W * C shape np_img_tr = np.transpose(np_img, (1, 2, 0)) plt.imshow(np_img_tr, interpolation='nearest')X_grid = utils.make_grid(X_train[:20], nrow=4, padding=2) #batch가 포함된 dataloader 이미지 텐서들을 도중에 보고자 할 때 사용print(X_grid.shape)show(X_grid)","link":"/2021/10/21/pytorch_training/"},{"title":"MLP 모델 설명 및 MLP방식 데이터 시각화","text":"MLP 모델이란? 퍼셉트론이 지니고 있는 한계(비선형 분류 문제 해결)를 극복하기 위해 여러 Layer를 쌓아올린 MLP(Multi Layer Perceptron)가 등장함. 간단히 비교하면, 퍼셉트론은 Input Layer와 Output Layer만 존재하는 형태입니다. MLP는 Input과 Output 사이에 Hidden Layer를 추가합니다. 즉, MLP는 이러한 Hidden Layer를 여러겹으로 쌓게 되는데, 이를 MLP 모델이라고 부릅니다. MLP 모델을 활용한 MNIST 모델 개발 MLP 모델 순서대로 코드를 구현합니다. Step 1. 모듈 불러오기123456import numpy as npimport matplotlib.pyplot as pltimport torchimport torch.nn as nnimport torch.nn.functional as Ffrom torchvision import transforms, datasets Step 2. 딥러닝 모델 설계 시 필요한 장비 세팅123456if torch.cuda.is_available(): DEVICE = torch.device('cuda')else: DEVICE = torch.device('cpu')print(&quot;PyTorch Version:&quot;, torch.__version__, ' Device:', DEVICE) PyTorch Version: 1.9.0+cu102 Device: cuda 12BATCH_SIZE = 32 # 데이터가 32개로 구성되어 있음. EPOCHS = 10 # 전체 데이터 셋을 10번 반복해 학습함. Step 3. 데이터 다운로드 torchvision 내 datasets 함수 이용하여 데이터셋 다운로드 합니다. ToTensor() 활용하여 데이터셋을 tensor 형태로 변환 한 픽셀은 0~255 범위의 스칼라 값으로 구성, 이를 0~1 범위에서 정규화 과정 진행 DataLoader는 일종의 Batch Size 만큼 묶음으로 묶어준다는 의미 Batch_size는 Mini-batch 1개 단위를 구성하는 데이터의 개수 12345678910111213141516train_dataset = datasets.MNIST(root = &quot;../data/MNIST&quot;, train = True, download = True, transform = transforms.ToTensor())test_dataset = datasets.MNIST(root = &quot;../data/MNIST&quot;, train = False, transform = transforms.ToTensor())train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle=True)test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle=False) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value=''))) Extracting ../data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz Failed to download (trying next): HTTP Error 503: Service Unavailable Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value=''))) Extracting ../data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz Failed to download (trying next): HTTP Error 503: Service Unavailable Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value=''))) Extracting ../data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz Failed to download (trying next): HTTP Error 503: Service Unavailable Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value=''))) Extracting ../data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw /usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.) return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s) step 4. 데이터 확인 및 시각화 데이터를 확인하고 시각화를 진행합니다. 32개의 이미지 데이터에 label 값이 각 1개씩 존재하기 때문에 32개의 값을 갖고 있음 1234for (X_train, y_train) in train_loader: print('X_train:', X_train.size(), 'type:', X_train.type()) print('y_train:', y_train.size(), 'type:', y_train.type()) break X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor y_train: torch.Size([32]) type: torch.LongTensor 1234567pltsize = 1plt.figure(figsize=(10 * pltsize, pltsize))for i in range(10): plt.subplot(1, 10, i + 1) plt.axis('off') plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap=&quot;gray_r&quot;) plt.title('Class: ' + str(y_train[i].item())) step 5. MLP 모델 설계 torch 모듈을 이용해 MLP를 설계합니다. 12345678910111213141516171819class Net(nn.Module): ''' Forward Propagation 정의 ''' def __init__(self): super(Net, self).__init__() self.fc1 = nn.Linear(28 * 28 * 1, 512) # (가로 픽셀 * 세로 픽셀 * 채널 수) 크기의 노드 수 설정 Fully Connected Layer 노드 수 512개 설정 self.fc2 = nn.Linear(512, 256) # Input으로 사용할 노드 수는 512으로, Output 노드수는 256개로 지정 self.fc3 = nn.Linear(256, 10) # Input 노드수는 256, Output 노드수는 10개로 지정 def forward(self, x): x = x.view(-1, 28 * 28) # 1차원으로 펼친 이미지 데이터 통과 x = self.fc1(x) x = F.sigmoid(x) x = self.fc2(x) x = F.sigmoid(x) x = self.fc3(x) x = F.log_softmax(x, dim = 1) return x step 6. 옵티마이저 목적 함수 설정 Back Propagation 설정 위한 목적 함수 설정 1234model = Net().to(DEVICE)optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum=0.5)criterion = nn.CrossEntropyLoss() # output 값과 원-핫 인코딩 값과의 Loss print(model) Net( (fc1): Linear(in_features=784, out_features=512, bias=True) (fc2): Linear(in_features=512, out_features=256, bias=True) (fc3): Linear(in_features=256, out_features=10, bias=True) ) step 7. MLP 모델 학습 MLP 모델을 학습 상태로 지정하는 코드를 구현 1234567891011121314def train(model, train_loader, optimizer, log_interval): model.train() for batch_idx, (image, label) in enumerate(train_loader): # 모형 학습 image = image.to(DEVICE) label = label.to(DEVICE) optimizer.zero_grad() # Optimizer의 Gradient 초기화 output = model(image) loss = criterion(output, label) loss.backward() # back propagation 계산 optimizer.step() if batch_idx % log_interval == 0: print(&quot;Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loass: {:.6f}&quot;.format(Epoch, batch_idx * len(image), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) step 8. 검증 데이터 확인 함수1234567891011121314151617def evaluate(model, test_loader): model.eval() test_loss = 0 correct = 0 with torch.no_grad(): for image, label in test_loader: image = image.to(DEVICE) label = label.to(DEVICE) output = model(image) test_loss += criterion(output, label).item() prediction = output.max(1, keepdim = True)[1] correct += prediction.eq(label.view_as(prediction)).sum().item() test_loss /= len(test_loader.dataset) test_accuracy = 100. * correct / len(test_loader.dataset) return test_loss, test_accuracy 모델 평가 시, Gradient를 통해 파라미터 값이 업데이트되는 현상 방지 위해 torch.no_grad() Gradient의 흐름 제어 step 9. MLP 학습 실행1234for Epoch in range(1, EPOCHS + 1): train(model, train_loader, optimizer, log_interval=200) test_loss, test_accuracy = evaluate(model, test_loader) print(&quot;\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n&quot;.format(Epoch, test_loss, test_accuracy)) /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead. warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;) Train Epoch: 1 [0/60000(0%)] Train Loass: 2.343919 Train Epoch: 1 [6400/60000(11%)] Train Loass: 2.304868 Train Epoch: 1 [12800/60000(21%)] Train Loass: 2.276658 Train Epoch: 1 [19200/60000(32%)] Train Loass: 2.320047 Train Epoch: 1 [25600/60000(43%)] Train Loass: 2.309569 Train Epoch: 1 [32000/60000(53%)] Train Loass: 2.293312 Train Epoch: 1 [38400/60000(64%)] Train Loass: 2.264061 Train Epoch: 1 [44800/60000(75%)] Train Loass: 2.311200 Train Epoch: 1 [51200/60000(85%)] Train Loass: 2.261489 Train Epoch: 1 [57600/60000(96%)] Train Loass: 2.260837 [EPOCH: 1], Test Loss: 0.0698, Test Accuracy: 36.43 % Train Epoch: 2 [0/60000(0%)] Train Loass: 2.233048 Train Epoch: 2 [6400/60000(11%)] Train Loass: 2.196863 Train Epoch: 2 [12800/60000(21%)] Train Loass: 2.173305 Train Epoch: 2 [19200/60000(32%)] Train Loass: 2.120425 Train Epoch: 2 [25600/60000(43%)] Train Loass: 2.023674 Train Epoch: 2 [32000/60000(53%)] Train Loass: 1.936951 Train Epoch: 2 [38400/60000(64%)] Train Loass: 1.738194 Train Epoch: 2 [44800/60000(75%)] Train Loass: 1.493235 Train Epoch: 2 [51200/60000(85%)] Train Loass: 1.547187 Train Epoch: 2 [57600/60000(96%)] Train Loass: 1.400939 [EPOCH: 2], Test Loss: 0.0402, Test Accuracy: 60.40 % Train Epoch: 3 [0/60000(0%)] Train Loass: 1.429194 Train Epoch: 3 [6400/60000(11%)] Train Loass: 1.178954 Train Epoch: 3 [12800/60000(21%)] Train Loass: 0.970049 Train Epoch: 3 [19200/60000(32%)] Train Loass: 1.105888 Train Epoch: 3 [25600/60000(43%)] Train Loass: 0.926736 Train Epoch: 3 [32000/60000(53%)] Train Loass: 0.794726 Train Epoch: 3 [38400/60000(64%)] Train Loass: 0.828843 Train Epoch: 3 [44800/60000(75%)] Train Loass: 0.872613 Train Epoch: 3 [51200/60000(85%)] Train Loass: 0.713790 Train Epoch: 3 [57600/60000(96%)] Train Loass: 0.464628 [EPOCH: 3], Test Loss: 0.0243, Test Accuracy: 76.67 % Train Epoch: 4 [0/60000(0%)] Train Loass: 0.507696 Train Epoch: 4 [6400/60000(11%)] Train Loass: 0.635314 Train Epoch: 4 [12800/60000(21%)] Train Loass: 0.636553 Train Epoch: 4 [19200/60000(32%)] Train Loass: 0.875113 Train Epoch: 4 [25600/60000(43%)] Train Loass: 0.558601 Train Epoch: 4 [32000/60000(53%)] Train Loass: 0.462972 Train Epoch: 4 [38400/60000(64%)] Train Loass: 0.630431 Train Epoch: 4 [44800/60000(75%)] Train Loass: 0.428842 Train Epoch: 4 [51200/60000(85%)] Train Loass: 0.826000 Train Epoch: 4 [57600/60000(96%)] Train Loass: 0.508183 [EPOCH: 4], Test Loss: 0.0182, Test Accuracy: 83.32 % Train Epoch: 5 [0/60000(0%)] Train Loass: 0.576632 Train Epoch: 5 [6400/60000(11%)] Train Loass: 0.437238 Train Epoch: 5 [12800/60000(21%)] Train Loass: 0.942570 Train Epoch: 5 [19200/60000(32%)] Train Loass: 0.412996 Train Epoch: 5 [25600/60000(43%)] Train Loass: 0.362784 Train Epoch: 5 [32000/60000(53%)] Train Loass: 0.677201 Train Epoch: 5 [38400/60000(64%)] Train Loass: 0.706629 Train Epoch: 5 [44800/60000(75%)] Train Loass: 0.587188 Train Epoch: 5 [51200/60000(85%)] Train Loass: 0.584579 Train Epoch: 5 [57600/60000(96%)] Train Loass: 0.602702 [EPOCH: 5], Test Loss: 0.0147, Test Accuracy: 86.63 % Train Epoch: 6 [0/60000(0%)] Train Loass: 0.388631 Train Epoch: 6 [6400/60000(11%)] Train Loass: 0.571896 Train Epoch: 6 [12800/60000(21%)] Train Loass: 0.287511 Train Epoch: 6 [19200/60000(32%)] Train Loass: 0.394190 Train Epoch: 6 [25600/60000(43%)] Train Loass: 0.264939 Train Epoch: 6 [32000/60000(53%)] Train Loass: 0.495090 Train Epoch: 6 [38400/60000(64%)] Train Loass: 0.274051 Train Epoch: 6 [44800/60000(75%)] Train Loass: 0.299830 Train Epoch: 6 [51200/60000(85%)] Train Loass: 0.450571 Train Epoch: 6 [57600/60000(96%)] Train Loass: 0.257513 [EPOCH: 6], Test Loss: 0.0129, Test Accuracy: 87.99 % Train Epoch: 7 [0/60000(0%)] Train Loass: 0.377794 Train Epoch: 7 [6400/60000(11%)] Train Loass: 0.630070 Train Epoch: 7 [12800/60000(21%)] Train Loass: 0.320578 Train Epoch: 7 [19200/60000(32%)] Train Loass: 0.658281 Train Epoch: 7 [25600/60000(43%)] Train Loass: 0.643368 Train Epoch: 7 [32000/60000(53%)] Train Loass: 0.420115 Train Epoch: 7 [38400/60000(64%)] Train Loass: 0.687097 Train Epoch: 7 [44800/60000(75%)] Train Loass: 0.430246 Train Epoch: 7 [51200/60000(85%)] Train Loass: 0.343727 Train Epoch: 7 [57600/60000(96%)] Train Loass: 0.577327 [EPOCH: 7], Test Loss: 0.0120, Test Accuracy: 88.78 % Train Epoch: 8 [0/60000(0%)] Train Loass: 0.530810 Train Epoch: 8 [6400/60000(11%)] Train Loass: 0.278406 Train Epoch: 8 [12800/60000(21%)] Train Loass: 0.140812 Train Epoch: 8 [19200/60000(32%)] Train Loass: 0.471123 Train Epoch: 8 [25600/60000(43%)] Train Loass: 0.415495 Train Epoch: 8 [32000/60000(53%)] Train Loass: 0.534980 Train Epoch: 8 [38400/60000(64%)] Train Loass: 0.318894 Train Epoch: 8 [44800/60000(75%)] Train Loass: 0.444783 Train Epoch: 8 [51200/60000(85%)] Train Loass: 0.211995 Train Epoch: 8 [57600/60000(96%)] Train Loass: 0.358874 [EPOCH: 8], Test Loss: 0.0113, Test Accuracy: 89.73 % Train Epoch: 9 [0/60000(0%)] Train Loass: 0.423838 Train Epoch: 9 [6400/60000(11%)] Train Loass: 0.225967 Train Epoch: 9 [12800/60000(21%)] Train Loass: 0.348597 Train Epoch: 9 [19200/60000(32%)] Train Loass: 0.397753 Train Epoch: 9 [25600/60000(43%)] Train Loass: 0.199611 Train Epoch: 9 [32000/60000(53%)] Train Loass: 0.269096 Train Epoch: 9 [38400/60000(64%)] Train Loass: 0.311267 Train Epoch: 9 [44800/60000(75%)] Train Loass: 0.575633 Train Epoch: 9 [51200/60000(85%)] Train Loass: 0.246814 Train Epoch: 9 [57600/60000(96%)] Train Loass: 0.272062 [EPOCH: 9], Test Loss: 0.0108, Test Accuracy: 89.94 % Train Epoch: 10 [0/60000(0%)] Train Loass: 0.399807 Train Epoch: 10 [6400/60000(11%)] Train Loass: 0.282056 Train Epoch: 10 [12800/60000(21%)] Train Loass: 0.270553 Train Epoch: 10 [19200/60000(32%)] Train Loass: 0.605585 Train Epoch: 10 [25600/60000(43%)] Train Loass: 0.333442 Train Epoch: 10 [32000/60000(53%)] Train Loass: 0.395121 Train Epoch: 10 [38400/60000(64%)] Train Loass: 0.676208 Train Epoch: 10 [44800/60000(75%)] Train Loass: 0.170694 Train Epoch: 10 [51200/60000(85%)] Train Loass: 0.160667 Train Epoch: 10 [57600/60000(96%)] Train Loass: 0.381771 [EPOCH: 10], Test Loss: 0.0105, Test Accuracy: 90.28 % train 함수 실행하면, model은 기존에 정의한 MLP 모델, train_loader는 학습 데이터, optimizer는 SGD, log_interval은 학습이 진행되면서 mini-batch index를 이용해 과정을 모니터링할 수 있도록 출력함. 학습 완료 시, Test Accuracy는 90% 수준의 정확도를 나타냄.","link":"/2021/10/21/step02_2_MLP/"},{"title":"논문 분석","text":"분석 논문: 논문 요약부cnn 정확도 향상 가능 특징들이 많음 대형 Dataset에서는 특징들의 조합을 test, 이론적 정당성이 있는 지에 대한 검증이 필요함 why? 일부기능은 특정 모델,특정 문제에 대해서만 작동하거나 소규모 Dataset에서만 작동함 보편적 특징은 WRC(Weighted-Residual-Connections),CSP(Cross-Stage-Partial-connections),CmBN(Cross mini-BatchNormalization),SAT(Self-adversarial-training),d Mish-activation 등 있음. 위의 특징 활성화,mosaic 데이터 증강, CmBN, Drop Block 정규화 및 clou 손실 등 새 기능을 사용하고, 일부를 결합하여 새로운 결과를 달성할 것임. 본론부CNN 기반 물체 탐지기는 권장 프로그램에만 적용 &gt;경우에 따른 권장 프로그램 형식이 다름 주차 자리 감지 시스템: 느리고 정확 차량 충돌 감지 시스템: 빠르고 덜 정확 실시간 객체 검출기 정확도 향상 시 힌트 생성 추천 시스템에 사용가능 독립 process관리, 인구유입 감소 시스템에도 사용 가능 기존 GPU는 낮은 가격으로 대량 사용 허용 &lt;-&gt; 현대 인공신경망은 대량의 GPU 필요 기존 GPU에 실시간 작동 CNN을 생성함 (현대 신경망 방식 문제점 완화) 위 사진에서 볼 수 있듯이 실시간, 고품질, 신뢰성 객체 탐지 연구 주요 목표 생산 시스템에서 객체 검출기의 빠른 동작 속도를 설계,병렬 계산을 위한 최적화 진행 효율적 , 강력한 물체 탐지 모델 개발 탐지 훈련동안 최첨단 Bag-of-Freebies 와 Bag-of-specials 영향을 검증. 최첨단 방식을 변형(수정), 단일 GPU 훈련에 적합하도록 함.","link":"/2021/10/21/%EB%85%BC%EB%AC%B8%EB%B6%84%EC%84%9D/"}],"tags":[],"categories":[{"name":"개인 프로젝트","slug":"개인-프로젝트","link":"/categories/%EA%B0%9C%EC%9D%B8-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/"},{"name":"개인적 내용","slug":"개인적-내용","link":"/categories/%EA%B0%9C%EC%9D%B8%EC%A0%81-%EB%82%B4%EC%9A%A9/"},{"name":"머신러닝","slug":"머신러닝","link":"/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/"},{"name":"YOLO 논문 분석","slug":"YOLO-논문-분석","link":"/categories/YOLO-%EB%85%BC%EB%AC%B8-%EB%B6%84%EC%84%9D/"}]}