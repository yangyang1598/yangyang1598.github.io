{"pages":[],"posts":[{"title":"The first day I made hexo","text":"github 연동 hexo 생성 1일차","link":"/2021/10/19/hello-world/"},{"title":"team프로젝트 코드","text":"team project main code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459import myopencv as myimport cv2, copyimport numpy as npdef binary(thresold, binary_img): binary = np.zeros_like(binary_img) binary[(binary_img &gt;= thresold[0]) &amp; (binary_img &lt;= thresold[1])] = 255 return binary passdef babo(img,src,dst): height, width = img.shape[:2] dst_size = (width, height) src = src * np.float32([width, height]) ## width, height 비율 값 dst = dst * np.float32(dst_size) ## 이미지를 적용할 화면 비율 M = cv2.getPerspectiveTransform(src, dst) ## 자를 이미지 좌표값 img_src = cv2.warpPerspective(img, M, dst_size) ## 잘라낼 이미지, 잘라낼 이미지 영역값, 잘라낼 이미지를 붙일 영역 사이즈 return img_src passdef Yolo(img, score, nms): height, width = img.shape[:2] yolo_net = cv2.dnn.readNet('YOLO/yolov3.weights', 'YOLO/yolov3.cfg') layer_names = yolo_net.getLayerNames() output_layers = [layer_names[i[0] - 1] for i in yolo_net.getUnconnectedOutLayers()] blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False) yolo_net.setInput(blob) outs = yolo_net.forward(output_layers) class_ids = [] confidences = [] boxes = [] for out in outs: for detection in out: scores = detection[5:] class_id = np.argmax(scores) confidence = scores[class_id] # 검출 신뢰도 if confidence &gt; 0.5: # Object detected # 검출기의 경계상자 좌표는 0 ~ 1로 정규화되어있으므로 다시 전처리 center_x = int(detection[0] * width) center_y = int(detection[1] * height) dw = int(detection[2] * width) dh = int(detection[3] * height) # Rectangle coordinate x = int(center_x - dw / 2) y = int(center_y - dh / 2) boxes.append([x, y, dw, dh]) confidences.append(float(confidence)) class_ids.append(class_id) indexes = cv2.dnn.NMSBoxes(boxes, confidences, score, nms) for i in range(len(boxes)): if i in indexes: x, y, w, h = boxes[i] label = str(classes[class_ids[i]]) score = confidences[i] text = f'{label} {score:.2f}' # 경계상자와 클래스 정보 투영 cv2.rectangle(img, (x, y), (x + w, y + h), (50, 50, 50), 2) cv2.rectangle(img, (x, y - 19), (int(x + len(text) * 2 * 4.5), y - 18 + len(text) * 2), (50, 50, 50), -1) cv2.putText(img, text, (x, y - 5), cv2.FONT_ITALIC, 0.5, (255, 255, 255), 2) return img passclasses = [&quot;person&quot;, &quot;bicycle&quot;, &quot;car&quot;, &quot;motorcycle&quot;, &quot;airplane&quot;, &quot;bus&quot;, &quot;train&quot;, &quot;truck&quot;, &quot;boat&quot;, &quot;traffic light&quot;, &quot;fire hydrant&quot;, &quot;stop sign&quot;, &quot;parking meter&quot;, &quot;bench&quot;, &quot;bird&quot;, &quot;cat&quot;, &quot;dog&quot;, &quot;horse&quot;, &quot;sheep&quot;, &quot;cow&quot;, &quot;elephant&quot;, &quot;bear&quot;, &quot;zebra&quot;, &quot;giraffe&quot;, &quot;backpack&quot;, &quot;umbrella&quot;, &quot;handbag&quot;, &quot;tie&quot;, &quot;suitcase&quot;, &quot;frisbee&quot;, &quot;skis&quot;, &quot;snowboard&quot;, &quot;sports ball&quot;, &quot;kite&quot;, &quot;baseball bat&quot;, &quot;baseball glove&quot;, &quot;skateboard&quot;, &quot;surfboard&quot;, &quot;tennis racket&quot;, &quot;bottle&quot;, &quot;wine glass&quot;, &quot;cup&quot;, &quot;fork&quot;, &quot;knife&quot;, &quot;spoon&quot;, &quot;bowl&quot;, &quot;banana&quot;, &quot;apple&quot;, &quot;sandwich&quot;, &quot;orange&quot;, &quot;broccoli&quot;, &quot;carrot&quot;, &quot;hot dog&quot;, &quot;pizza&quot;, &quot;donut&quot;, &quot;cake&quot;, &quot;chair&quot;, &quot;couch&quot;, &quot;potted plant&quot;, &quot;bed&quot;, &quot;dining table&quot;, &quot;toilet&quot;, &quot;tv&quot;, &quot;laptop&quot;, &quot;mouse&quot;, &quot;remote&quot;, &quot;keyboard&quot;, &quot;cell phone&quot;, &quot;microwave&quot;, &quot;oven&quot;, &quot;toaster&quot;, &quot;sink&quot;, &quot;refrigerator&quot;, &quot;book&quot;, &quot;clock&quot;, &quot;vase&quot;, &quot;scissors&quot;, &quot;teddy bear&quot;, &quot;hair drier&quot;, &quot;toothbrush&quot;]margin = 150nwindows = 9minpix = 1img_ = []count = 0frame_start = 0frame_count = 0frame = 0A = 0step = 1 # 한번에 넘어갈 프레임수line_len = 100road_width = 2.5_ = Trueleft_a, left_b, left_c = [], [], []right_a, right_b, right_c = [], [], []leftx_base_ = []rightx_base_ = []leftx_base_step = []rightx_base_step = []leftx_ = []lefty_ = []rightx_ = []righty_ = []left_fit_ = np.empty(3)right_fit_ = np.empty(3)name = ['REC_2021_10_09_10_16_45_F', 'REC_2021_10_09_10_17_45_F', 'REC_2021_10_09_10_18_45_F']Video = cv2.VideoCapture(f'video/1/{name[count]}.mp4')Out = cv2.VideoWriter('show_orginal_1.mp4', cv2.VideoWriter_fourcc(*'FMP4'), 30, (1920, 1080 + 270))frame_end = int(Video.get(cv2.CAP_PROP_FRAME_COUNT))passwhile True: frame_count += step _, img = Video.read() img_blur = cv2.blur(img, (5, 5), 0) img_hsv = cv2.cvtColor(img_blur, cv2.COLOR_BGR2HSV) img = my.Undistort(img, 'wide_dist_pickle.p') height, width = img.shape[:2] img_cut = np.zeros_like(img) if A == 0: A = 1 pass ## 블랙박스 TopLeft = (.4, .65) TopRight = (.55, .65) BottomLeft = (.0, .95) BottomRight = (.9, .95) ## 블랙박스 ## 흰색 white_lower = (15, 5, 90) white_upper = (255, 255, 255) ## 흰색 factor = np.float32([width, height]) src = np.float32([TopLeft, TopRight, BottomLeft, BottomRight]) dst = np.float32([(.0, .0), (1., .0), (.0, 1.), (1., 1.)]) cut = np.float32([TopLeft, TopRight, BottomRight, BottomLeft]) cut = np.int_(cut * factor) cv2.fillPoly(img_cut, [cut], (255, 255, 255)) img_src = cv2.bitwise_and(img_hsv, img_cut) img_temp = babo(img_src, src, dst) img_perspect = babo(img, src, dst) temp = np.zeros_like(img) temp_1 = copy.deepcopy(img_perspect) temp_2 = copy.deepcopy(img_perspect) temp_3 = copy.deepcopy(img_perspect) temp_4 = copy.deepcopy(img_perspect) temp_5 = copy.deepcopy(img_perspect) Yolo(img, 0.1, 0.4) img_white = cv2.inRange(img_temp, white_lower, white_upper) img_white_line = cv2.bitwise_and(img_perspect, img_perspect, mask=img_white) img_white_line_blur = cv2.blur(img_white_line, (3, 3), 1) img_hls = cv2.cvtColor(img_white_line_blur, cv2.COLOR_BGR2HLS) img_hls_h, img_hls_l, img_hls_s = cv2.split(img_hls) s_thresold = (120, 255) h_thresold = (150, 255) img_binary_1 = binary(h_thresold, img_hls_h) img_binary_2 = binary(s_thresold, img_hls_l) img_binary = cv2.addWeighted(img_binary_1, 1., img_binary_2, 1., 0) ## 네모 상자 그리기 histogram = np.sum(img_binary[height // 2:, :], axis=0) ## histogram 설명 : numpy.sum 설명 읽기 ## x,y 2차원 배열을 y축 반틈 아래 부분을 y축을 제거 하고 ## x축의 값만 더한 값 midpoint = int(histogram.shape[0] / 2) ## midpoint 설명 : histogram의 반틈 길이 좌,우 나누기 위함 leftx_base = np.argmax(histogram[:midpoint]) ## leftx_base 설명 : histogram의 0 ~ midpoint 중 제일 큰값 rightx_base = np.argmax(histogram[midpoint:]) + midpoint ## rightx_base 설명 : histogram의 midpoint ~ end 중 제일 큰값 leftx_base_.append(leftx_base) rightx_base_.append(rightx_base) leftx_base = np.int64(np.mean(leftx_base_[-10:])) rightx_base = np.int64(np.mean(rightx_base_[-10:])) window_height = int(height / nwindows) ## window_height 설명 : 사각형 범위 높이 겟수 nonzero = img_binary.nonzero() ## nonzero 설명 : 0이 아닌 값인 x, y 인덱스값 분리 nonzero_y = np.array(nonzero[0]) ## nonzero_y 설명 : y축의 0이 아닌 인덱스 nonzero_x = np.array(nonzero[1]) ## nonzero_x 설명 : x축의 0이 아닌 인덱스 leftx_current = leftx_base rightx_current = rightx_base left_lane_inds = [] right_lane_inds = [] # 네모 상자 그리기 for window in range(nwindows): win_y_low = height - (window + 1) * window_height win_y_high = height - window * window_height win_xleft_low = leftx_current - margin win_xleft_high = leftx_current + margin win_xright_low = rightx_current - margin win_xright_high = rightx_current + margin cv2.rectangle(temp, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (100, 255, 255), 3) cv2.rectangle(temp, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (100, 255, 255), 3) cv2.rectangle(temp_1, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (100, 255, 255), 3) cv2.rectangle(temp_1, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (100, 255, 255), 3) good_left_inds = ((nonzero_y &gt;= win_y_low) &amp; (nonzero_y &lt; win_y_high) &amp; (nonzero_x &gt;= win_xleft_low) &amp; (nonzero_x &lt; win_xleft_high)).nonzero()[0] ## good_left_inds 설명 : 왼쪽 사각형 범위 안에 x값의 0이 아닌 값 추출 good_right_inds = ((nonzero_y &gt;= win_y_low) &amp; (nonzero_y &lt; win_y_high) &amp; (nonzero_x &gt;= win_xright_low) &amp; (nonzero_x &lt; win_xright_high)).nonzero()[0] ## good_right_inds 설명 : 오른쪽 사각형 범위 안에 x값의 0이 아닌 값 추출 left_lane_inds.append(good_left_inds) ## left_lane_inds 설명 : good_left_inds 값을 left_lane_inds에 저장 right_lane_inds.append(good_right_inds) ## right_lane_inds 설명 : good_right_inds 값을 right_lane_inds 저장 leftx_base_step.append(leftx_current) rightx_base_step.append(rightx_current) if len(good_left_inds) &gt; minpix: leftx_current = int(np.mean(nonzero_x[good_left_inds])) ## leftx_current 설명 : nonzero_x 안에 good_left_inds 인덱스 값의 평균 값 pass elif len(good_left_inds) == 0: leftx_current = int(np.mean(leftx_base_step[-10:])) pass if len(good_right_inds) &gt; minpix: rightx_current = int(np.mean(nonzero_x[good_right_inds])) ## rightx_current 설명 : nonzero_x 안에 good_right_inds 인덱스 값의 평균 값 pass elif len(good_right_inds) == 0: rightx_current = int(np.mean(rightx_base_step[-10:])) pass # 네모 상자 그리기 # 네모 상자 그리기 left_lane_inds = np.concatenate(left_lane_inds) right_lane_inds = np.concatenate(right_lane_inds) ## left_lane_inds, right_lane_inds 설명 : 2차 배열을 1차 배열로 합침 leftx = nonzero_x[left_lane_inds] ## leftx 설명 : nonzero_x 안에 left_lane_inds 인덱스 값 lefty = nonzero_y[left_lane_inds] ## lefty 설명 : nonzero_y 안에 left_lane_inds 인덱스 값 rightx = nonzero_x[right_lane_inds] ## rightx 설명 : nonzero_x 안에 right_lane_inds 인덱스 값 righty = nonzero_y[right_lane_inds] ## righty 설명 : nonzero_y 안에 right_lane_inds 인덱스 값 leftx_.append(leftx) lefty_.append(lefty) rightx_.append(rightx) righty_.append(righty) if len(left_lane_inds) == 0: for i in range(len(leftx_)): if len(leftx_[-(i + 1)]) != 0: leftx = leftx_[-(i + 1)] lefty = lefty_[-(i + 1)] print(&quot;왼쪽 에러&quot;) break pass pass if len(right_lane_inds) == 0: for i in range(len(rightx_)): if len(rightx_[-(i + 1)]) != 0: rightx = rightx_[-(i + 1)] righty = righty_[-(i + 1)] print(&quot;오른쪽 에러&quot;) break pass pass pass left_fit = np.polyfit(lefty, leftx, 2) ## left_fit 설명 : np.polyfit를 통해 lefty, leftx 값에 대한 차수가 2인 값을 반환 (곡선) right_fit = np.polyfit(righty, rightx, 2) ## right_fit 설명 : np.polyfit를 통해 righty, rightx 값에 대한 차수가 2인 값을 반환 (곡선) left_a.append(left_fit[0]) left_b.append(left_fit[1]) left_c.append(left_fit[2]) right_a.append(right_fit[0]) right_b.append(right_fit[1]) right_c.append(right_fit[2]) left_fit_[0] = np.mean(left_a[-10:]) left_fit_[1] = np.mean(left_b[-10:]) left_fit_[2] = np.mean(left_c[-10:]) right_fit_[0] = np.mean(right_a[-10:]) right_fit_[1] = np.mean(right_b[-10:]) right_fit_[2] = np.mean(right_c[-10:]) ## 설명 : 아래와 같다 # left_fit_[0] = left_fit[0] # left_fit_[1] = left_fit[1] # left_fit_[2] = left_fit[2] # right_fit_[0] = right_fit[0] # right_fit_[1] = right_fit[1] # right_fit_[2] = right_fit[2] ploty = np.linspace(0, height - 1, height) ## ploty 설명 : np.linspace 통해 0 ~ 이미지 height 값 까지 값을 순서대로 배열 생성 left_fitx = left_fit_[0] * ploty ** 2 + left_fit_[1] * ploty + left_fit_[2] ## left_fitx 설명 : X = a[0] * y^2 + a[1] * y + a[2] // 2차 다항식 회귀 공식 right_fitx = right_fit_[0] * ploty ** 2 + right_fit_[1] * ploty + right_fit_[2] ## right_fitx 설명 : X = a[0] * y^2 + a[1] * y + a[2] // 2차 다항식 회귀 공식 mid_fitx = (left_fitx + right_fitx) // 2 temp[nonzero_y[left_lane_inds], nonzero_x[left_lane_inds]] = [255, 0, 100] temp[nonzero_y[right_lane_inds], nonzero_x[right_lane_inds]] = [0, 100, 255] temp_2[nonzero_y[left_lane_inds], nonzero_x[left_lane_inds]] = [255, 0, 100] temp_2[nonzero_y[right_lane_inds], nonzero_x[right_lane_inds]] = [0, 100, 255] left = np.array([np.transpose(np.vstack([left_fitx, ploty]))]) right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))]) mid = np.array([np.transpose(np.vstack([mid_fitx, ploty]))]) points = np.hstack((left, right)) left_center = np.int_(np.mean(left_fitx)) right_center = np.int_(np.mean(right_fitx)) mid_center = np.int_(np.mean(mid_fitx)) road_center = width // 2 road_pixel = road_width / (right_center - left_center) error = mid_center - road_center error_pixel = error * road_pixel cv2.line(temp_3, (left_center + 10, height // 2 + line_len), (left_center - 10, height // 2 - line_len), (255, 0, 255), 30) cv2.line(temp_3, (right_center + 10, height // 2 + line_len), (right_center - 10, height // 2 - line_len), (255, 0, 255), 30) cv2.line(temp_3, (mid_center + 10, height // 2 + line_len), (mid_center - 10, height // 2 - line_len), (255, 0, 255), 30) cv2.line(temp_3, (width // 2 - 10, height // 2), (width // 2 + 20, height), (255, 0, 255), 10) cv2.line(temp_3, (mid_center, height // 2), (width // 2 - 10, height // 2), (255, 255, 255), 30) cv2.polylines(temp, np.int_(points), False, (0, 255, 255), 10) cv2.polylines(temp_3, np.int_(points), False, (0, 255, 255), 10) cv2.polylines(temp_3, np.int_(mid), False, (0, 255, 255), 10) cv2.fillPoly(temp, np.int_(points), (0, 255, 0)) cv2.fillPoly(temp_4, np.int_(points), (0, 255, 0)) cv2.line(temp, (left_center + 10, height // 2 + line_len), (left_center - 10, height // 2 - line_len), (255, 0, 255), 30) cv2.line(temp, (right_center + 10, height // 2 + line_len), (right_center - 10, height // 2 - line_len), (255, 0, 255), 30) cv2.line(temp, (mid_center + 10, height // 2 + line_len), (mid_center - 10, height // 2 - line_len), (255, 0, 255), 30) cv2.line(temp, (width // 2 - 10, height // 2), (width // 2 + 20, height), (255, 0, 255), 10) cv2.line(temp, (mid_center, height // 2), (width // 2 - 10, height // 2), (255, 255, 255), 30) temp = babo(temp, dst, src) img_result = cv2.addWeighted(img, 1., temp, 0.4, 0) if error &gt; 0: cv2.putText(img_result, f'right : {abs(error_pixel):.2f}m', (width // 2 - 50, height // 2 + 200), cv2.FONT_ITALIC, 0.5, (0, 0, 255), 2) elif error &lt; 0: cv2.putText(img_result, f'left : {abs(error_pixel):.2f}m', (width // 2 - 50, height // 2 + 200), cv2.FONT_ITALIC, 0.5, (0, 0, 255), 2) elif error == 0: cv2.putText(img_result, f'center', (width // 2, height // 2), cv2.FONT_ITALIC, 0.5, (0, 0, 255), 2) cv2.putText(img_result, f'{frame} / {frame_end}', (20, height - 40), cv2.FONT_ITALIC, 0.5, (255, 255, 255), 2) cv2.putText(img_result, f'{frame_count} / {frame_end * 3}', (20, height - 20), cv2.FONT_ITALIC, 0.5, (255, 255, 255), 2) a = cv2.hconcat([temp_1, temp_2, temp_3, temp_4]) _, top = my.imgsize(a, 1920) result = cv2.vconcat([top, img_result]) _, result = my.imgsize(result, 1920) my.imgshow(&quot;result&quot;, result, 1000) Out.write(result) key = cv2.waitKey(1) frame += step Video.set(cv2.CAP_PROP_POS_FRAMES, frame) if Video.get(cv2.CAP_PROP_POS_FRAMES) ==\\ Video.get(cv2.CAP_PROP_FRAME_COUNT): if count &lt; 2: count += 1 frame = 0 # frame_count = 0 Video = cv2.VideoCapture(f'video/1/{name[count]}.mp4') print(name[count]) Video.set(cv2.CAP_PROP_POS_FRAMES, 0) frame_count = frame_end * count frame_end = int(Video.get(cv2.CAP_PROP_FRAME_COUNT)) print(f&quot;{count}&quot;) elif count &gt; 2: print(f&quot;저장 완료&quot;) break pass if key == 115: ## s cv2.waitKey(0) pass elif key == 102: ## f frame_start = int(input(&quot;&quot;)) frame_count += frame_start frame = frame_start Video.set(cv2.CAP_PROP_POS_FRAMES, frame_start) cv2.waitKey(0) elif key == 114: ## r Video.set(cv2.CAP_PROP_POS_FRAMES, frame_end - 1) frame = frame_end - 1 elif key == 27: Video.release() Out.release() cv2.destroyAllWindows() break pass passVideo.release()Out.release()cv2.destroyAllWindows()pass team project myopencv 파일12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import cv2, pickleimport numpy as npdef Url(link): n = np.fromfile(link, dtype=np.uint8) return ndef standard(src, size): ## src = 불러온 이미지 소스 , size = 변경할 크기 max = 0 if size &lt; src.shape[0] or size &lt; src.shape[1]: if src.shape[0] &gt; src.shape[1]: max = src.shape[0] elif src.shape[1] &gt; src.shape[0]: max = src.shape[1] else: max = src.shape[0] else: # print(&quot;확대 불가&quot;) max = size # print(&quot;원래이미지 h, w&quot;,src.shape[0],src.shape[1]) scale = size / max return scaledef imgsize(src, size): ## src = 불러온 이미지 소스 , size = 변경할 크기 scale = standard(src, size) return scale,cv2.resize(src, None, fx=scale, fy=scale)def imgcolor(src,Colortype=cv2.IMREAD_COLOR): ## src = 불러온 이미지 소스 , Colortype = 변경할 이미지 컬러(미지정시 자동 BGR컬로) return cv2.cvtColor(src,Colortype)def Imgread(link, size, Colortype=cv2.IMREAD_COLOR): ## url = 이미지 링크 , size = 변경할 크기 , 받아올 이미지 컬러타입 , Colortype = 변경할 이미지 컬러(미지정시 자동 BGR컬로) url = Url(link) if size &gt; 0: src = cv2.imdecode(url, Colortype) scale, result = imgsize(src, size) print(&quot;이미지 재지정 h, w&quot;, result.shape[0], result.shape[1]) return scale,result elif size == 0: src = cv2.imdecode(url, Colortype) return srcdef Undistort(img, url='camera_cal/wide_dist_pickle.p'): ## 보정 파라미터 사용 with open(url, mode='rb') as f: file = pickle.load(f) mtx = file['mtx'] dist = file['dist'] return cv2.undistort(img, mtx, dist, None, mtx)def binary(thresold, binary_img): binary = np.zeros_like(binary_img) binary[(binary_img &gt;= thresold[0]) &amp; (binary_img &lt;= thresold[1])] = 255 return binary passdef imgshow(title, src , size = 500): _, img = imgsize(src,size) return cv2.imshow(title, img) passdef imgmerge(img): img_src = cv2.merge([img, img, img]) return img_src passif __name__ ==&quot; __main__&quot;: pass","link":"/2021/10/19/team%20code/"},{"title":"개발자로써 익혀야 할 것들","text":"리눅스 명령어 모음git bash를 다루기 위해서는 리눅스 명령어 More info: LINUX 명령어 모음 머신러닝 직군 질문모음개발자 및 머신러닝 직군의 면접 예상 질문 More info: 개발자 면접질문","link":"/2021/10/19/tip/"}],"tags":[],"categories":[]}